### About Lookback RNN

...

### File Structure

In these examples we store all our data in ~/magenta_data. Feel free to choose a different directory on your local machine. To get an idea of how data is used and generated by the model, this is what your file structure will look like after you have trained your model and generated some melodies with it.

```
~
└── magenta_data
    ├── lookback_rnn
    │   ├── generated
    │   │   ├── 2016-07-08_21-34-55_01.mid
    │   │   ├── 2016-07-08_21-34-55_02.mid
    │   │   ├── 2016-07-08_21-34-55_03.mid
    │   │   └── ...
    │   │       (Original melodies generated by your trained model.)
    │   ├── logdir
    │   │   ├── run1
    │   │   │   ├── eval
    │   │   │   │   └── events.out.tfevents.1467425436
    │   │   │   │       (Saved evaluation data used by TensorBoard.)
    │   │   │   └── train
    │   │   │       ├── checkpoint
    │   │   │       ├── events.out.tfevents.1467422802
    │   │   │       ├── events.out.tfevents.1467423145
    │   │   │       ├── events.out.tfevents.1467423162
    │   │   │       ├── graph.pbtxt
    │   │   │       ├── model.ckpt-78
    │   │   │       ├── model.ckpt-78.meta
    │   │   │       ├── model.ckpt-80
    │   │   │       ├── model.ckpt-80.meta
    │   │   │       ├── model.ckpt-83
    │   │   │       └── model.ckpt-83.meta
    │   │   │           (Saved checkpoints, graph data, and training
    │   │   │            data used by TensorBoard.)
    │   │   ├── run2
    │   │   │   ├── eval
    │   │   │   │   └── ...
    │   │   │   └── train
    │   │   │       └── ...
    │   │   └── ...
    │   │       (Multiple runs can be stored in logdir. Each run can
    │   │        use different hyperparameters or a different dataset
    │   │        if multiple datasets are created. All runs can be
    │   │        visualized together in TensorBoard.)
    │   └── sequence_examples
    │       ├── classical_melodies_train.tfrecord
    │       └── classical_melodies_eval.tfrecord
    │           (TFRecord files of SequenceExamples. These are used
    │            to train and evalutate the model. Each
    │            SequenceExample has a sequence of inputs and a
    │            sequence of labels that represent a melody. These
    │            melodies are extracted from the NoteSequences in
    │            ~/magenta_data/note_sequences/classical.tfrecord.)
    ├── midi
    │   └── classical
    │       ├── bach_1.mid
    │       ├── bach_2.mid
    │       ├── bach_3.mid
    │       └── ...
    │       (Your collection of MIDI files.)
    └── note_sequences
        └── classical.tfrecord
            (A TFRecord file of NoteSequences. Each NoteSequence
             contains data (notes, tempos, time signatures) that
             represets the data in single midi file. These
             NoteSequences are created from the midi files in
             ~/magenta_data/midi/classical.)
```

### Create NoteSequences

To start, we'll need a collection of MIDI files. In this example we assume we have a collection of classical music MIDI files in ~/magenta_data/midi/classical/. Our first step will be to convert these MIDI files to NoteSequences. These NoteSequences will contain the same music data that the MIDI files do, but the data will be in a [protocol buffer](https://developers.google.com/protocol-buffers/) format, which is easier to work with. Run the script below to convert your collection of MIDI files into a TFRecord file of NoteSequences.

```
bazel run //magenta:convert_midi_dir_to_note_sequences -- \
--midi_dir=~/magenta_data/midi/classical \
--output_file=~/magenta_data/note_sequences/classical.tfrecord \
--recursive
```

### Create SequenceExamples

SequenceExamples are fed into the model during training and evaluation. Each SequenceExample will contain a sequence of inputs and sequence of labels that will represent a melody. Run the script below to extract melodies from the NoteSequences and save them in a TFRecord file of SequenceExamples.

```
bazel run //magenta/models:lookback_rnn_create_dataset -- \
--input=~/magenta_data/note_sequences/classical.tfrecord \
--train_output=~/magenta_data/lookback_rnn/sequence_examples/classical_melodies_train.tfrecord \
--eval_output=~/magenta_data/lookback_rnn/sequence_examples/classical_melodies_eval.tfrecord \
--eval_ratio=0.10
```

### Train and Evaluate the Model

Build lookback_rnn_train first so that it can be run multiple times in parallel.

```
bazel build //magenta/models:lookback_rnn_train
```

--run_dir is the directory where you want checkpoints and TensorBoard data for this run to be stored. --sequence_example_file is the TFRecord file of SequenceExamples that we want to use. --num_training_steps is how many update steps to take before exiting. --hparams can optionally be used to specify hyperparameters other than the defaults.

Run the script below to start a training job.

```
./bazel-bin/magenta/models/lookback_rnn_train \
--run_dir=~/magenta_data/lookback_rnn/logdir/run1 \
--sequence_example_file=~/magenta_data/lookback_rnn/sequence_examples/classical_melodies_train.tfrecord \
--num_training_steps=20000 \
--hparams="{'batch_size':64}"
```

Optionally run an eval job in parallel with the training job. --sequence_example_file should point to the separate eval dataset. Include the --eval flag to signal that this is an eval job, and that the model should only be evaluated without updating any of the weights.

```
./bazel-bin/magenta/models/lookback_rnn_train \
--run_dir=~/magenta_data/lookback_rnn/logdir/run1 \
--sequence_example_file=~/magenta_data/lookback_rnn/sequence_examples/classical_melodies_eval.tfrecord \
--num_training_steps=20000 \
--eval
```

Run TensorBoard to view the train and eval data.

```
tensorboard --logdir=~/magenta_data/lookback_rnn/logdir
```

Go to [http://localhost:6006](http://localhost:6006) to view the TensorBoard dashboard.

### Generate Melodies

Melodies can be generated during or after training. To generate melodies, we need to load a checkpoint file. In this example we point to the directory ~/magenta_data/lookback_rnn/logdir/run1. The most recent checkpoint in .../run1/train will be used.

--output_dir is where the generated MIDI files will be saved. --num_steps is how long each melody will be in 16th steps (128 steps = 8 bars). --num_outputs is the number of melodies that will be generated.

At least one note needs to be fed to the model before it can start generating consecutive notes. We can use --primer_melody to specify a priming melody as a Python list. The values of the list are ints that follow the melodies_lib.Melody format (-2 = no event, -1 = note-off event, values 0 through 127 = note-on event for that MIDI pitch). For example --primer_melody="[60, -2, 60, -2, 67, -2, 67, -2]" would prime the model with the first four notes of Twinkle Twinkle Little Star. Instead of using --primer_melody, you can use --primer_midi, which should be the path to a MIDI file that contains the priming melody. If neither --primer_melody nor --primer_midi are used, a random note from the model's note range will be chosen as the first note, then the remaining notes will be generated by the model. In the example below we prime the melody with a single note-on event for the pitch C4.

```
bazel run //magenta/models:lookback_rnn_generate \
--run_dir=~/magenta_data/lookback_rnn/logdir/run1 \
--output_dir=~/magenta_data/lookback_rnn/generated \
--num_steps=128 \
--num_outputs=10 \
--primer_melody="[60]"
```
